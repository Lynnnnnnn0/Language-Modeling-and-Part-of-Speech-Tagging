# Language-Modeling-and-Part-of-Speech-Tagging
* Built the n-gram models to tag part of speech
* Calculated the log-probability of each sentence in the Brown training data with uni-, bi-, and trigram models
* Implemented linear interpolation among the three n-gram models, and compared the perplexity with the originals
* Implemented the forward algorithm for Hidden Markov Model taggers to compute the likelihood of a word sequence being generated by a HMM
* Implemented the Viterbi algorithm for HMM taggers to find the highest scoring tag sequence for a given sentence
* detailed instruction provided as in "Assignment1"
